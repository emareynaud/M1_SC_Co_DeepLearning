{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSPCom-KmApV"
      },
      "source": [
        "# DL2 - CNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klAltGp8ycek"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/images/cnn\">\n",
        "    <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />\n",
        "    View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/cnn.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/cnn.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "    View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/images/cnn.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLGkt5qiyz4E"
      },
      "source": [
        "On utilise ici un CNN (https://developers.google.com/machine-learning/glossary/#convolutional_neural_network) (CNN) pour claiifier les images [CIFAR ](https://www.cs.toronto.edu/~kriz/cifar.html), avec l'API  [Keras Sequential API](https://www.tensorflow.org/guide/keras/overview), en juste quelques lignes de code.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7KBpffWzlxH"
      },
      "source": [
        "### Importer TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAve6DCL4JH4"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRFxccghyMVo"
      },
      "source": [
        "### Préparer la base CIFAR10\n",
        "\n",
        "Cette base contient 60 000 images couleur réparties équitablement en 10 classes.\n",
        "On divise en 50 000 images d'apprentissage, et 10 000 de test, et on les normalise :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWoEqyMuXFF4"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wArwCTJJlUa"
      },
      "source": [
        "### Explorons les données\n",
        "\n",
        "On fait afficher les 25 premières images avec leurs labels, et les 10 classes qu'on apprend :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3PAELE2eSU9"
      },
      "source": [
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[train_labels[i][0]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsYOzCZ5at38"
      },
      "source": [
        "Et une seule image :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb8h5xouarEM"
      },
      "source": [
        "plt.imshow(train_images[12])\n",
        "label = train_labels[12]\n",
        "print(label)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oewp-wYg31t9"
      },
      "source": [
        "**Création du CNN : **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN0fyx8sa8wC"
      },
      "source": [
        "print(train_images[11])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hQvqXpNyN3x"
      },
      "source": [
        "On emplile des couches de type [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) et [MaxPooling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D) layers.\n",
        "\n",
        "Les images en entrée sont des tenseurs de 32 * 32 * couleur.\n",
        "Couleur est le code RGB de la couleur du pixel.\n",
        "D'ou un parametre input_shape qui est de 32 * 32 * 3\n",
        "\n",
        "Les couches Conv2D sont de la forme :\n",
        "layers.conv2D(nombre de filtres - ou cartes - , ( largeur du noyau, hauteur du noyau - ou kernel suze).\n",
        "\n",
        "Les couches Maxpool2D prennent pour parametres la taille de la grille considérée pour sortir le maximum.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9YmGQBQPrdn"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvDVFkg-2DPm"
      },
      "source": [
        "Voici l'architecture du réseau :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-C4XBg4UTJy"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j-AXYeZ2GO5"
      },
      "source": [
        "La premiere couche mène à 32 cartes 30*30. Ensuite on applique une opération MaxPool sur chacune de ces cartes, avec une grille 2*2 : il en résulte 32 cartes 15*15 : on divise par 4 la taille de l'information.\n",
        "PLus on va \"profond\" dans le réseau, plus l'info se résume. Et donc, plus on peut rajouter de couches sans perdre de temps de calcul, car c'est les dimensions des données qui sont couteuses en temps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_v8sVOtG37bT"
      },
      "source": [
        "### La touche finale : les couches denses \"fully connected\" :\n",
        "On rajoute en sortie de la couche conv2D-2 une couche qui permet de faire la classification, elle est totalement connectée.\n",
        "Il faut dans un premier temps applatir la sortie de la couche conv2D-2 qui est un tenseur en 3 dimensions (4*4*64), pour qu'il devienne un vecteur 1D. On ajoute ensuite une ou plusieurs couches Dense (ici 2).\n",
        "\n",
        "La base CIFAR a 10 classes à apprendre, il nous faut donc 10 neurones de sortie (softmax).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRs95d6LUVEi"
      },
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipGiQMcR4Gtq"
      },
      "source": [
        "Voici l'architecture finale du modèle de DL :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Yu_m-TZUWGX"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3odqfHP4M67"
      },
      "source": [
        "### Compiler et entrainer le modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdDzI75PUXrG"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=100,\n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKgyC5K_4O0d"
      },
      "source": [
        "### Evaluer le modèle\n",
        "En bleu, précision sur le set d'apprentissage, en orange sur le set de validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtyDF0MKUcM7"
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LvwaKhtUdOo",
        "colab": {
          "background_save": true
        }
      },
      "source": [
        "print(test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cfJ8AR03gT5"
      },
      "source": [
        "Précision de 70% environ !\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05wxWTtHe7Rh"
      },
      "source": [
        "On teste maintenant le modèle, avec une image qu'on importe nous même :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNgDATwke9W1"
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(32, 32))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "\n",
        "\n",
        "  print(classes)\n",
        "\n",
        "classes2 = np.argmax(classes, axis=1)\n",
        "\n",
        "if classes2[0] == 0:\n",
        "        print('It is an airplane')\n",
        "elif classes2[0] == 1:\n",
        "        print('It is an automobile')\n",
        "elif classes2[0] == 2:\n",
        "        print('It is a bird')\n",
        "elif classes2[0] == 3:\n",
        "        print('It is a cat')\n",
        "elif classes2[0] == 4:\n",
        "        print('It is a deer')\n",
        "elif classes2[0] == 5:\n",
        "        print('It is a dog')\n",
        "elif classes2[0] == 6:\n",
        "        print('It is a frog')\n",
        "elif classes2[0] == 7:\n",
        "        print('It is a horse')\n",
        "elif classes2[0] == 8:\n",
        "        print('It is a ship')\n",
        "elif classes2[0] == 9:\n",
        "        print('It is a truck')\n",
        "else:\n",
        "        print('Can\\'t recognize the image')\n",
        "\n",
        "print('done')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}